<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>  | Validating Results</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.32.2" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    <link href='https://szeitlin.github.io/dist/main.css' rel='stylesheet' type="text/css" />
    
      
    

    

    <meta property="og:title" content="Validating Results" />
<meta property="og:description" content="I don&rsquo;t believe truth is a finite value. Truth is what we know right now. Every ten years or so, a major discovery gets overturned. Scientists are just people, and we&rsquo;re wrong a lot.
So one of the scariest things about doing research, or predictions, is trying to convince yourself, and other people, that what you think you&rsquo;ve discovered is &lsquo;real&rsquo;.
Or at least real enough, right now, to be believable." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://szeitlin.github.io/posts/statistics/validating-results/" />



<meta property="article:published_time" content="2016-04-15T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2016-04-15T00:00:00&#43;00:00"/>











<meta itemprop="name" content="Validating Results">
<meta itemprop="description" content="I don&rsquo;t believe truth is a finite value. Truth is what we know right now. Every ten years or so, a major discovery gets overturned. Scientists are just people, and we&rsquo;re wrong a lot.
So one of the scariest things about doing research, or predictions, is trying to convince yourself, and other people, that what you think you&rsquo;ve discovered is &lsquo;real&rsquo;.
Or at least real enough, right now, to be believable.">


<meta itemprop="datePublished" content="2016-04-15T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2016-04-15T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1687">



<meta itemprop="keywords" content="experimental design," />
<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Validating Results"/>
<meta name="twitter:description" content="I don&rsquo;t believe truth is a finite value. Truth is what we know right now. Every ten years or so, a major discovery gets overturned. Scientists are just people, and we&rsquo;re wrong a lot.
So one of the scariest things about doing research, or predictions, is trying to convince yourself, and other people, that what you think you&rsquo;ve discovered is &lsquo;real&rsquo;.
Or at least real enough, right now, to be believable."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://szeitlin.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      
    </a>
    <div class="flex-l items-center">
      
      








    </div>
  </div>
</nav>

    </div>
  </header>


    <main class="pb7" role="main">
      
  <div class="flex-l mt2 mw8 center">
    <article class="center cf pv5 ph3 ph4-ns mw7">
      <header>
        <p class="f6 b helvetica tracked">
          POSTS
        </p>
        <h1 class="f1">
          Validating Results
        </h1>
      </header>
      <div class="nested-copy-line-height lh-copy f4 nested-links nested-img mid-gray">
        

<p>I don&rsquo;t believe truth is a finite value. Truth is what we know right now. Every ten years or so, a major discovery gets overturned. Scientists are just people, and we&rsquo;re wrong a lot.</p>

<p>So one of the scariest things about doing research, or predictions, is trying to convince yourself, and other people, that what you think you&rsquo;ve discovered is &lsquo;real&rsquo;.</p>

<p>Or at least real enough, right now, to be believable. Whenever I do a project, I hope my findings will stand the test of time, at least long enough to be useful.</p>

<p>One piece of advice that has always stuck with me is that there&rsquo;s no such thing as the perfect experiment (or model). No matter how well you do it, no matter how many controls you do, no matter how many replicates, every approach has limitations. It might be biased in ways you know about, and in ways that are not obvious because of variables you don&rsquo;t know about yet.</p>

<p>How do we get around that, and generate solid insights without wasting a lot of time?</p>

<ol>
<li>Start from what is known. Don&rsquo;t reinvent the wheel. Trust, but verify.</li>
<li>Design your experiments wisely.</li>
<li>Use orthogonal approaches to cover your bases, and test your assumptions.</li>
<li>Get input from other people.</li>
</ol>

<hr />

<h2 id="start-from-what-is-known">Start from what is known.</h2>

<h3 id="read-everything">Read Everything</h3>

<p>When I was in college, the Chair of my Department was big on reading. He gave us 2 thick textbooks the summer before our senior seminar with him, and told us to read them cover to cover. Then when we wrote our final papers, he told us to read every paper we could find on our subject of choice.</p>

<p>It sounds ridiculous, but it&rsquo;s great advice. If you don&rsquo;t know what&rsquo;s been done before, how do you know you&rsquo;re actually doing something new? If it&rsquo;s been attempted before, how do you know you won&rsquo;t make all the same mistakes? How do you know you&rsquo;re not missing out on all kinds of tips and tricks that might save you a lot of time and confusion?</p>

<h3 id="trust-but-verify">Trust but verify</h3>

<p>Perhaps most importantly, if there&rsquo;s some way to verify your assumptions, like say if someone has done part or all of your project before, try to get your hands on their results. You&rsquo;re going to want to know how your results compare with theirs. Can you understand why your results might be different from what they reported? Have you improved on previous methods? Are you able to recapitulate their results using their methods? Using yours? Maybe their results are completely unreproducible. In that case, you shouldn&rsquo;t be trying to make your approach look like theirs. Or maybe your methods aren&rsquo;t very robust, in which case you have more work to do.</p>

<h2 id="design-your-experiments-wisely">Design your experiments wisely</h2>

<h3 id="pick-two">Pick two</h3>

<p>Choose at least two approaches. It&rsquo;s never a good idea to base a major conclusion on a single measurement, or even a single type of measurement made in triplicate.</p>

<p>Ideally, it&rsquo;s best to have a handful of orthogonal approaches. Then if the conclusions from each of these are consistent, you can feel pretty confident about your overall conclusion.</p>

<h3 id="have-a-testable-hypothesis">Have a testable hypothesis</h3>

<p>Do you know what you expect? Try examining your assumptions, and turn those into hypotheses. Are you trying to confirm a known result? Then you are testing whether you can reproduce that result. Set boundaries on how exact your answer should be. Does it have to be perfect? Or within 5%?  It really can be that simple.</p>

<h3 id="know-the-pros-and-cons-of-the-approaches-you-choose">Know the pros and cons of the approaches you choose</h3>

<p>Maybe you&rsquo;re debating about the best way to get data into your system. Your options are things like:</p>

<p>a) scan PDF files and have a 3rd party library parse them into text</p>

<p>b) have someone type in the values by hand</p>

<p>c) pay for access to a 3rd party database</p>

<p>The advantage of using the PDF files is that it&rsquo;s probably the cheapest solution. The disadvantage is that the parsing probably won&rsquo;t be perfect, and will require some additional validation, probably by a person, possibly by a person writing code to check the results.</p>

<p>Having someone type in the values by hand may be more accurate, but it depends on the person. You&rsquo;ll probably still need a second person, or some other method, to check for typos.</p>

<p>Paying for access to a 3rd party database might be the most expensive, but it also might be the most scalable long-term.</p>

<p>It also depends on whether the data is going to be used as samples (for experimentation, where there might not be a &lsquo;right answer&rsquo;), vs. as reference data (where you need the data to be as stable and accurate as possible).</p>

<h3 id="design-an-experiment-that-will-let-you-see-things-you-didn-t-know-to-look-for">Design an experiment that will let you see things you didn&rsquo;t know to look for</h3>

<p>In the example above, options (b) and &copy; might provide additional insights that (a) won&rsquo;t give you. Computers only know to look for what you tell them, but people tend to notice everything. Databases often contain additional data that you didn&rsquo;t think you would need, but which might be interesting to you and relevant to your project. Choosing your data sources and process of collection can provide additional insights that you might otherwise miss out on.</p>

<h3 id="sample-selection">Sample selection</h3>

<h4 id="choose-samples-that-represent">Choose samples that represent:</h4>

<p><strong>Positive controls:</strong> known responders. Examples that reproducibly support your original hypothesis.</p>

<p><strong>Negative controls:</strong> known non-responders. Examples that reproducibly do not fit in your target category. They should be examples of things that cannot respond for different reasons. These are perhaps the most important to get right, especially in multivariate systems. If you&rsquo;re not sure what to use, they can be &ldquo;leave-one-out&rdquo;, if the thing you&rsquo;re leaving out is critical to the event you&rsquo;re observing.</p>

<p>For example, if you were doing a PCR to detect DNA in a sample of water, your negative controls include:</p>

<ol>
<li>a sample of a different piece of DNA in water</li>
<li>sample of clean water</li>
<li>a sample that lacks the polymerase enzyme for the detection reaction</li>
<li>a sample that lacks the oligonucleotide primers specific for your target DNA</li>
</ol>

<p>** Edge cases:** examples of things that you know are hard to identify</p>

<p>To use the PCR example again, this might include a sample that you know contains your target DNA, but with a rearrangement that destroys half of it.</p>

<p>Edge cases are critical for determining the sensitivity and selectivity of your approach. It&rsquo;s also essential to set your metrics based on whether you want to include or filter out certain types of edge cases.</p>

<p><strong>Main samples:</strong> examples of what you expect to occur most commonly, which contain your target category and which can be sorted or otherwise identified (if only you can get the right methods and models in place!). Usually this is a mixed population, and you have some hypotheses about what variables might play a role in segmentation, even if your hypothesis is just &ldquo;there is more than one sub-population in this group.&rdquo; (Hint: if you look carefully, there is usually more than one sub-population in a group)</p>

<h3 id="sample-size">Sample size</h3>

<p>Choose samples that are big enough to be representative. For edge cases, sometimes one is enough.
For positive and negative controls, you usually need a few, to check for variability within the populations, and also to compare against your main sample. But it all depends on the distribution of your system. If it&rsquo;s not a normal distribution, or your controls are Gaussian but your main samples are not, you&rsquo;re going to need a bigger sample to train your model, if you want it to perform well in real tests.</p>

<p>It&rsquo;s also worth thinking about how your test population and controls, which are usually static, will represent the real thing, which might be streaming or otherwise changing over time. Are there known variables, like season, that might require you to periodically update your test samples? Your model can&rsquo;t account for what it hasn&rsquo;t seen.</p>

<h3 id="metrics-to-evaluate-whether-it-worked-or-not">Metrics to evaluate whether it worked or not</h3>

<p>Before you begin any experiment, think about how you&rsquo;re going to evaluate what you observe. If you have a hypothesis, your metric for success might be whether your data are consistent with your hypothesis. If you don&rsquo;t, maybe you have a threshold for what you&rsquo;d consider a believable observation. How are you going to measure that? Is it going to affect the sample sizes you choose for your test populations (probably)?</p>

<h2 id="get-input">Get input</h2>

<p>Ask other people to discuss the models you&rsquo;re considering. Look at what other people have done in similar situations. Review your work with interested parties, while it&rsquo;s still in progress, so you can make modifications if any of your assumptions are wrong, if new insights become available, or if any of the priorities have changed.</p>

<p>And then when you think you&rsquo;re done, review it again. And again. Get other people to help you look for possible mistakes. Everybody makes mistakes. It doesn&rsquo;t mean you&rsquo;re not working hard or not good at your job. Sometimes it just means you&rsquo;re too close to the problem, or you&rsquo;ve been looking at it too long. Make sure to build time into your process so you can take a break, even if it&rsquo;s just to sleep on it for one night, and then look everything over again with fresh eyes.</p>

<h2 id="you-might-still-be-wrong">You might still be wrong</h2>

<p>Always remember that you might be wrong. Always re-examine all your assumptions, and all the shortcomings of the approaches you&rsquo;ve used. Sometimes this will open up new avenues for investigation, or help you shore up your findings. Sometimes someone else will come to you with evidence that you&rsquo;ve made a mistake. There will be bugs in your code. That&rsquo;s ok. Just take a deep breath and see what&rsquo;s changed with this new information.</p>

<p>Ultimately, all you can do is your best, and then you have to let it go. And you have to be ok with that. If you&rsquo;re not ok with knowing that you&rsquo;re human and imperfect, you&rsquo;ll be paralyzed with fear and unable to do anything that hasn&rsquo;t already been done before. That&rsquo;s ok, it just means doing this kind of work is probably not the right path for you.</p>

      </div>
    </article>
    <aside class="ph3 mt2 mt6-ns">
      







  <div class="bg-light-gray pa3">
    <ul>
      <li class="list b mb3">
        26 More Posts
      </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/cross-account-access-aws/" class="link ph2 pv2 db black">
            Cross-account access with AWS
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/things-i-learned-about-pyspark-the-hard-way/" class="link ph2 pv2 db black">
            Things I learned about Pyspark the hard way
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/airflow/airflow-for-hands-off-etl/" class="link ph2 pv2 db black">
            Airflow
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/statistics/probability-binning-simple-and-fast/" class="link ph2 pv2 db black">
            Probability binning: simple and fast
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/within-every-tutorial-is-another-tutorial/" class="link ph2 pv2 db black">
            A tutorial within a tutorial on building reusable models with scikit-learn
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/shuffling-the-deck-an-interview-question/" class="link ph2 pv2 db black">
            Shuffling the deck: an interview experience
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/statistics/validating-results/" class="link ph2 pv2 db black o-50">
            Validating Results
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/test-driven-data-pipelining/" class="link ph2 pv2 db black">
            Test-driven data pipelining
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/data-pipelining-with-pandas-automating-lookup-and-update/" class="link ph2 pv2 db black">
            Data pipelining with pandas
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/biking_data/biking-data-from-xml-to-plots-revised/" class="link ph2 pv2 db black">
            Biking data from XML to analysis, revised
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/biking_data/device-data/" class="link ph2 pv2 db black">
            Working with device data
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/biking_data/biking-data-from-xml-to-plots-part-2/" class="link ph2 pv2 db black">
            Biking data from XML to analysis, part 2
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/biking_data/biking-data-from-xml-to-plots-part-3/" class="link ph2 pv2 db black">
            Biking data from XML to analysis, part 3
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/biking_data/biking-data-from-xml-to-plots-part-4/" class="link ph2 pv2 db black">
            Biking data from XML to analysis, part 4
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/things-i-learned-about-zip-files-last-week/" class="link ph2 pv2 db black">
            Things I learned about zip files
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/career_transition/things-i-learned-studying-the-cell-cycle-in-cancer/" class="link ph2 pv2 db black">
            Things I learned studying the cell cycle in cancer
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/recruiting/still-looking-for-a-job-advice-on-recruiting-/" class="link ph2 pv2 db black">
            Advice on recruiting
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/automating-user-friendly-documentation-using-selenium-/" class="link ph2 pv2 db black">
            Automating user-friendly documentation with Selenium
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/biking_data/bike-data-from-xml-to-plots/" class="link ph2 pv2 db black">
            Biking data from XML to analysis, part 1
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/career_transition/faq-why-and-how-i-learned-to-code/" class="link ph2 pv2 db black">
            FAQ: why and how I learned to code
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/fun-with-failing/" class="link ph2 pv2 db black">
            Fun with text file encodings
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/game-plan-for-conferences-with-high-risk-of-harassment/" class="link ph2 pv2 db black">
            Game plan for attending conferences with a high risk of harassment
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/career_transition/python-where-to-start/" class="link ph2 pv2 db black">
            Python: where to start
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/quick-and-dirty-plot-your-data-on-a-map/" class="link ph2 pv2 db black">
            Quick and dirty: plot your data on a map with python
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/engineering/recursion-excursion/" class="link ph2 pv2 db black">
            Recursion excursion
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/robustness-lessons-from-doing-applied-bench-science/" class="link ph2 pv2 db black">
            Robustness: lessons from applied bench science
          </a>
        </li>
      
        <li class="list f5 w-100 hover-bg-white nl1">
          
          <a href="/posts/career_skills/tips-on-giving-presentations/" class="link ph2 pv2 db black">
            Tips on giving presentations
          </a>
        </li>
      
    </ul>
  </div>


    </aside>
  </div>

    </main>
    <footer class="bg-near-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://szeitlin.github.io/" >
    &copy; 2018 
  </a>
  








  </div>
</footer>

    <script src="https://szeitlin.github.io/dist/app.bundle.js" async></script>

  </body>
</html>
